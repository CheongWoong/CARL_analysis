{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# Define a scaling factor\n",
    "scale_factor = 1.5\n",
    "\n",
    "# Update default font sizes by multiplying with the scaling factor\n",
    "rcParams['font.size'] *= scale_factor       # Default font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "map = {0.1: 0, 0.5: 1, 1.0: 2, 1.5: 3, 2.0: 4}\n",
    "\n",
    "# Convert string keys to tuples and prepare the grid\n",
    "def prepare_grid(data, size):\n",
    "    grid_data = np.zeros((size, size))\n",
    "    normalizer = np.sum(list(data.values()))\n",
    "    for key, value in data.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map[i], map[j]] = value / normalizer\n",
    "    return grid_data\n",
    "\n",
    "def prepare_grid_diff(data1, data2, size):\n",
    "    grid_data = np.zeros((size, size))\n",
    "    normalizer1 = np.sum(list(data1.values()))\n",
    "    normalizer2 = np.sum(list(data2.values()))\n",
    "\n",
    "    for key, value in data1.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map[i], map[j]] = value / normalizer1\n",
    "    for key, value in data2.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map[i], map[j]] = grid_data[map[i], map[j]] / (value / normalizer2)\n",
    "    return grid_data\n",
    "\n",
    "def plot_grid(grid, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(grid, annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel('mass', fontsize=18)\n",
    "    plt.ylabel('length', fontsize=18)\n",
    "    # # Setting the tick marks\n",
    "    plt.yticks(np.arange(len(map))+0.5, labels=list(map.keys()), rotation=0)\n",
    "    plt.xticks(np.arange(len(map))+0.5, labels=list(map.keys()), rotation=0)\n",
    "    plt.savefig(f\"output/CARLPendulum/context_weights.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load data from a file\n",
    "data = {}\n",
    "for checkpoint in [15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    with open(f'../../runs/training/seed_1/CARLPendulum/train/stacked_bdr/checkpoints/{checkpoint}_context_rarity_record.json', 'r') as f:\n",
    "        data[f'{checkpoint}_BDR'] = json.load(f)\n",
    "    with open(f'../../runs/training/seed_1/CARLPendulum/train/stacked_bdr/checkpoints/{checkpoint}_context_rarity_record_baseline.json', 'r') as f:\n",
    "        data[f'{checkpoint}_baseline'] = json.load(f)\n",
    "\n",
    "# Plot grids for each checkpoint\n",
    "for checkpoint in [15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000][-1:]:\n",
    "    baseline_data = data.get(f'{checkpoint}_baseline')\n",
    "    bdr_data = data.get(f'{checkpoint}_BDR')\n",
    "    \n",
    "    # if baseline_data:\n",
    "    #     baseline_grid = prepare_grid(baseline_data, 5)\n",
    "    #     plot_grid(baseline_grid, f'{checkpoint} - Baseline')\n",
    "    \n",
    "    # if bdr_data:\n",
    "    #     bdr_grid = prepare_grid(bdr_data, 5)\n",
    "    #     plot_grid(bdr_grid, f'{checkpoint} - BDR')\n",
    "\n",
    "    if baseline_data and bdr_data:\n",
    "        diff_grid = prepare_grid_diff(bdr_data, baseline_data, 5)\n",
    "        # plot_grid(diff_grid, f'{checkpoint} - diff')\n",
    "        plot_grid(diff_grid, f'Pendulum - Context Weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "map1 = {0.1: 0, 0.5: 1, 1.0: 2, 1.5: 3, 2.0: 4}\n",
    "map2 = {1: 0, 5: 1, 10: 2, 15: 3, 20: 4}\n",
    "\n",
    "# Convert string keys to tuples and prepare the grid\n",
    "def prepare_grid(data, size):\n",
    "    grid_data = np.zeros((size, size))\n",
    "    normalizer = np.sum(list(data.values()))\n",
    "    for key, value in data.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map1[i], map2[j]] = value / normalizer\n",
    "    return grid_data\n",
    "\n",
    "def prepare_grid_diff(data1, data2, size):\n",
    "    grid_data = np.zeros((size, size))\n",
    "    normalizer1 = np.sum(list(data1.values()))\n",
    "    normalizer2 = np.sum(list(data2.values()))\n",
    "\n",
    "    for key, value in data1.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map1[i], map2[j]] = value / normalizer1\n",
    "    for key, value in data2.items():\n",
    "        i, j = eval(key)\n",
    "        \n",
    "        grid_data[map1[i], map2[j]] = grid_data[map1[i], map2[j]] / (value / normalizer2)\n",
    "    return grid_data\n",
    "\n",
    "def plot_grid(grid, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(grid, annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel('gravity', fontsize=18)\n",
    "    plt.ylabel('friction', fontsize=18)\n",
    "    # # Setting the tick marks\n",
    "    plt.yticks(np.arange(len(map1))+0.5, labels=list(map1.keys()), rotation=0)\n",
    "    plt.xticks(np.arange(len(map2))+0.5, labels=list(map2.keys()), rotation=0)\n",
    "    plt.savefig(f\"output/CARLDmcWalkerEnv/context_weights.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load data from a file\n",
    "data = {}\n",
    "for checkpoint in [50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000]:\n",
    "    with open(f'../../runs/training/seed_1/CARLDmcWalkerEnv/train/stacked_bdr/checkpoints/{checkpoint}_context_rarity_record.json', 'r') as f:\n",
    "        data[f'{checkpoint}_BDR'] = json.load(f)\n",
    "    with open(f'../../runs/training/seed_1/CARLDmcWalkerEnv/train/stacked_bdr/checkpoints/{checkpoint}_context_rarity_record_baseline.json', 'r') as f:\n",
    "        data[f'{checkpoint}_baseline'] = json.load(f)\n",
    "\n",
    "# Plot grids for each checkpoint\n",
    "for checkpoint in [50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000][-1:]:\n",
    "    baseline_data = data.get(f'{checkpoint}_baseline')\n",
    "    bdr_data = data.get(f'{checkpoint}_BDR')\n",
    "    \n",
    "    # if baseline_data:\n",
    "    #     baseline_grid = prepare_grid(baseline_data, 5)\n",
    "    #     plot_grid(baseline_grid, f'{checkpoint} - Baseline')\n",
    "    \n",
    "    # if bdr_data:\n",
    "    #     bdr_grid = prepare_grid(bdr_data, 5)\n",
    "    #     plot_grid(bdr_grid, f'{checkpoint} - BDR')\n",
    "\n",
    "    if baseline_data and bdr_data:\n",
    "        diff_grid = prepare_grid_diff(bdr_data, baseline_data, 5)\n",
    "        # plot_grid(diff_grid, f'{checkpoint} - diff')\n",
    "        plot_grid(diff_grid, f'Walker - Context Weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
